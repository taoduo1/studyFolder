<h1>1.nginx</h1>
   1. nginx配置如下代码所示，每一个server 是一个配置监听的节点的端口，负载均衡配置是在 http配置里面 增加

   ``` text
   全局配置
   
   events {
           
   }
   
   http {
       // 负载均衡设置 test是名字
       upstream test{
           server 127.0.0.1:8080 weight:1;// 配置两台服务器 weight 权重 都为1时是轮询，权重越高被分配几率也就越大
           server 127.0.0.1:8080 weight:1;
       }
   
      server {
           listen       80; //监听的端口
           server_name  localhost;
           proxy_pass http://test //使用上面配置的负载均衡的名字
       } 
       
       server {
           listen       443; //监听的端口
           server_name  localhost; 
       } 
   }
  ```
<h1>2. redis</h1>

   1. 缓存雪崩，击穿，穿透
      1. 雪崩，多个数据集中过期，导致数据库同时承受大量请求
         解决方法：失效的时间设置一个范围内+随机值   
      2. 击穿，某些冷门key，突然变成热门，当这个key在失效的时候，持续的大并发穿破缓存直接进行数据库查询，导致性能下降
         ```java
          //1：增加双重检查锁
         public List<Object> getData(String key){
            Object data = redisService.get(key);
            if (data == null){
                synchronized (this){
                   data = redis.get(key);
                   if (data != null){
                       return data;
                   }
                   data = dbService.get(key);
                   if (data != null){
                      redisService.set(key,data);    
                   }
                }
            }
            retur data;
         }
         ```
   2. 穿透，redis和数据库中都没有这个数据就会导致查询一直去查数据库
         缓存查到的空数据，如果这个数据有更新，再更新redis中的值，同时增加过期时间，
         布隆过滤器
   3. 统计30天内用户登录的功能
      使用bitmap
      两种存储方式，1：使用key为日期，value为用户id，2使用key为用户id，value为天数
      是否可以考虑两种方式同时存储
   4. 统计双方的共同好友
      使用set进行存储，key为用户id，value为用户的好友的用户id
      redis提供了SinterStore，可以将两个set的交集放入另一个set中
      如果是大数据量的话，neo4j
      Hbase+Hadoop
   5. 防止重复下单
      使用setNx setNx如果redis中无值，返回true并保存成功，如果有值，返回false
      用户在下单的时候，setNx，key为当前用户id，值为当前用户token+商品url+业务类型 设置时间为5秒，如果redis有值，就下单失败，如果没有值，就下单成功
   6. 热点数据请求量大的问题
      使用本地缓存
      大的热点数据拆分为小数据，分摊到不同节点的redis上
      对key进行限流，限流中间件/rateLimiter 
      热点探测系统
   7. 大key问题（超过10Kb就是大key）
      拆分大key
      数据压缩，压缩后再存储
      开启堕性删除，
      使用scan替代keys
   8. 双写不一致如何解决 两个线程同时操作，第一个线程将数据库中数据修改为10， 更新缓存为10，在更新缓存之前，另一个线程执行较快，已经将数据库中数据修改为6，然后将缓存更新为6，这时候第一个线程会将缓存更新为10，导致缓存中数据与数据库中数据不一致
      加分布式锁
      用canal 中间价异步更新缓存
      设置一个短一点的过期时间
   9. redis删除策略 惰性删除和定期删除相结合
      惰性删除  redis中数据过期了，redis不会立刻删除它，而是在访问这条数据的时候去删除
      定期删除 redis后台有个定时任务，每隔100ms进行一次扫描，扫描一部分设置了过期时间的数据，并删除其中已经过期的数据
   10. redis的key和value的设计原则有哪些
       key
          key应该尽量短，尽量不超过256个字节，含义清晰
          确保唯一性并使用冒号“：”分层级组织管理，最好加上业务标识，例如 user:10001:profile
          避免热key，将热key分片处理
       value
          避免大对象存储，限制单个value的大小
          使用大对象进行压缩
       合理使用过期时间
       预估容量和并发
   11. 使用redis注意点
      优化redis的数据结构，选择合适的结构进行存储
      设置合理的过期时间
      使用持久化策略，结合RDB和AOF并配置定期备份保证数据安全
      监控和报警机制
      规模化和高可用，使用主从架构并且增加哨兵机制
      设计良好的命名空间
   12. 功能设计：
       1. 分布式锁：红锁
       2. 全局ID 雪花算法
       3. 限流 令牌桶 lua算法加redis
       4. 抽奖 redis+lua算法 使用has数据结构
       5. 点赞
       6. 签到
       7. 排行榜/热榜 ZSet 数据结构
       8. 登录及权限功能设计
<h1>9. 规则引擎</h1>

   1. 怎么引入项目中的

<h1>3. mq消息队列</h1>

   场景：上游下发信息到对外接口集群，对外接口集群需要对外发送消息，使用了mq组件，将消息放进下发表后，发送消息至mq，mq调用消息下发接口进行消息下发到客户手机app
   1. 消息不丢失，如果mq服务器重启了怎么办
   2. 大量消息突然进来，怎么处理
   3. 防止消息重复消费
   4. 如何保证消息队列可靠性
   5. 使用多个生产者和消费者怎么做的
    
   用户发送消息到商品   
   ‌简单模式（Simple Mode）。
       一个生产者、一个消费者、一个队列。
       消息只能被单个消费者处理，也称为点对点模式。
    ‌工作队列模式（Work Queue Mode）。
        一个生产者、多个消费者、一个队列。
        队列将消息分发给不同的消费者，适用于任务分配场景。
    ‌发布/订阅模式（Publish/Subscribe Mode）。
        生产者将消息发送到交换机，交换机广播给所有绑定的队列。
        使用Fanout交换机类型，实现消息的广播。
    ‌路由模式（Routing Mode）。
        生产者通过指定路由键（Routing Key）将消息发送到交换机。
        交换机根据路由键将消息路由到匹配的队列。
    ‌通配符模式（Topics Mode）。
        类似于路由模式，但支持通配符匹配路由键。
        使用*和#实现灵活的路由规则。
    RPC通信模式（RPC Mode）。
        支持远程过程调用，允许客户端发送请求并等待服务器响应。
        适用于需要同步通信的场景。
    ‌发布确认模式（Publisher Confirms Mode）。
        生产者发送消息后，等待Broker的确认。
        支持单独确认、批量确认和异步确认机制。



<h1>4. xxl job</h1>
   1. 如何做的，定时器如何调用到服务
   2. 原理
<h1>5. 多线程/线程池</h1>

<h1>6. es</h1>

<h1>7. mysql</h1>

<h1>8. activity工作流</h1>

项目中遇到的难点以及怎么去解决的
项目中最复杂的功能


