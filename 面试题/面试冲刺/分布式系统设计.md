# 分布式系统设计

## 服务注册发现（CAP理论下Eureka与 Nacos对比）
    CAP理论,C一致性（Consistency），A 可用性（Availability），P分区容错性（Partition Tolerance）,理论上这三点无法同时满足，
    C 一致性：所有节点在同一时刻看到的数据完全相同，即强一致性。
    A 可用性：系统在任何情况下均能响应请求（非错误或超时），即使部分节点故障。例如，社交媒体应用需保证用户随时刷新动态
    P 分区容错性: 系统在网络分区（节点间通信中断）时仍能继续运行。例如，跨地域数据中心需容忍网络波动
- 三者不可兼得的根本原因
  - 选择CP：若保证一致性，需等待分区节点数据同步完成才能响应请求，导致可用性下降。例如，ZooKeeper在选举Leader期间会暂停服务
  - 选择AP：若保证可用性，允许节点返回旧数据，牺牲一致性。例如，Eureka在网络分区时仍接受服务注册，但不同节点数据可能短暂不一致
  - CA场景的局限性：仅在单机或无网络分区的理想环境下成立，无法满足分布式系统的现实需求
- 典型应用场景与系统举例
  - CP系统
    - 金融交易系统（如银行核心系统）：需强一致性，即使停机维护也要保证转账金额准确
    - 分布式协调工具（如ZooKeeper、etcd）：通过Raft协议实现强一致性，用于Kubernetes元数据管理等场景
  - AP系统：
    - 高并发服务发现（如Eureka、Nacos AP模式）：容忍短暂不一致，优先保障服务注册与发现的可用性
    - 缓存与消息队列（如Redis集群、RabbitMQ）：通过最终一致性支持高吞吐量
  - AC系统
    - 单机数据库（如MySQL单实例）：无网络分区问题，但无法扩展为分布式架构
- Eureka 严格遵循AP模式 优先保证可用性（A）和分区容错性（P）
  - 在网络分区（如节点宕机或网络中断）时，Eureka会进入自我保护模式，保留所有注册信息以避免服务不可用，但可能导致不同节点间的数据短暂不一致
  - 采用内存存储，无持久化机制，依赖客户端定时上报心跳（默认30秒），服务列表通过定时拉取（默认30秒）更新，存在秒级延迟
  - 通过增量数据同步减少网络开销，但节点间数据最终一致需依赖异步复制
  - 节点宕机后，其他节点仍可接受服务注册与查询，但新节点加入需手动同步数据，恢复时间较长
  - 适合高可用性优先的云原生场景，如电商、社交等对短暂数据不一致容忍度较高的业务
  - Eureka仅支持HTTP心跳检测
  - Eureka提供区域（Region/Zone）两级隔离
- Nacos 支持AP和CP
  - AP模式：通过Distro协议实现最终一致性，适用于临时实例注册（需客户端心跳续约），容忍短暂数据不一致以保障高可用
    - AP模式下：数据分片存储，节点间异步复制，支持服务列表变更的主动推送（Push模式），更新时效性更高
    - AP模式：Leader节点宕机时，秒级自动选举新Leader，服务注册不受影响
    - AP模式：适用于大多数微服务场景，如互联网应用、实时性要求较高的服务发现
  - CP模式：通过Raft协议保证强一致性，适用于持久化实例或配置中心场景，确保数据实时一致，但牺牲部分可用性（如Leader选举期间服务注册阻塞）
    - CP模式下：基于Raft协议实现强一致性，所有写操作需经Leader节点同步到多数派节点，保证数据实时一致
    - CP模式：Leader选举期间（约3-10秒），服务注册短暂阻塞，客户端通过重试机制自动恢复
    - CP模式：用于金融交易、配置管理等强一致性要求的场景
  - Nacos支持TCP主动探测（非临时实例）和HTTP心跳，提供更精准的健康状态判断
  - Nacos支持Namespace、Group、Service三级隔离，细粒度更高
- Eureka以简单、高可用见长，适合传统Spring Cloud生态；而Nacos凭借模式切换、实时推送和强一致性能力，更适合复杂业务场景（如混合云、动态配置管理）。
实际选型需权衡业务对一致性、可用性及运维成本的需求

## 熔断降级策略（Hystrix vs Sentinel）
- Hystrix
  - 核心目标：专注于容错与故障隔离，通过熔断、线程池隔离、降级等手段阻止级联故障
  - 实现方式：基于命令模式（HystrixCommand）封装请求，每个资源独立线程池或信号量隔离，牺牲部分性能换取强隔离性
  - 局限性：2018年后停止更新，配置复杂且扩展性较差，适用于传统Spring Cloud体系
  - Hystrix适用场景
    - 传统微服务架构：需强隔离性（如金融交易系统）
    - 存量系统维护：已有Hystrix集成且无性能瓶颈的场景
  - 选择Hystrix的情况
    - 现有Spring Cloud Netflix体系且无性能瓶颈。
    - 需要严格的线程池隔离（如资源敏感型服务）

- Sentinel
  - 核心目标：以流量控制为核心，扩展至熔断降级、系统负载保护等场景，支持动态规则配置与多语言生态
  - 实现方式：轻量级非阻塞设计，通过资源埋点（注解或API）统计实时指标，支持QPS、响应时间、热点参数等多维度控制
  - 优势：持续更新，与Spring Cloud Alibaba深度集成，适用于云原生环境和高性能场景
  - Sentinel适用场景
    - 高并发互联网应用：如电商秒杀、支付系统（如双11支持12万QPS）
    - 动态规则需求：需实时调整阈值或灰度发布
  - 优先选择Sentinel的情况
    - 高吞吐量需求（如10万+ QPS）
    - 需灵活的动态规则管理（如双11 实时调优）
    - 多语言支持或云原生环境（如Kubernetes）
## 分布式事务
  - 2PC（两阶段提交）
    - 1阶段：事务协调者询问事务参与者是否准备好，执行但不提交
    - 2阶段：通知所有的事务参与者提交
    - 异常情况
      - 1阶段异常：某个事务参与者在1阶段出现异常/协调者没有收到参与者的确认，协调者在2阶段通知所有参与者全部回滚
      - 2阶段异常：协调者发送commit后，某个参与者未收到消息/失败，协调者多次重试再次发送提交请求
  - 3PC（三阶段提交）
    - 1阶段：协调者向所有参与者发送询问请求，确认参与者的状态(网络状态，服务是否可用)
    - 2阶段：若所有参与者返回确认后，向各个参与者发送preCommit请求，要求参与者执行事务但不提交
    - 3阶段：若所有参与者返回确认后，向各个参与者发送提交请求，
    - 异常情况：
      - 1阶段异常：某个参与者在1阶段返回错误或超时，向所有参与者发送终止请求
      - 2阶段异常：某个事务在2阶段返回错误或异常时，向所有参与者发送回滚请求
      - 3阶段异常：协调者宕机，则参与者默认提交事务，参与者宕机则协调者重新发送提交请求
    - 相比2阶段提交的优点
      - 减少同步阻塞：2阶段提交，如果协调者发送1阶段请求后宕机，参与者会无限阻塞
      - 缓解单点故障风险：2阶段提交，参与者故障，其他参与者仍然会执行操作，浪费性能，协调者故障，事务无法恢复，3阶段中协调者和参与者都有主动推进事务的能力
      - 降低数据不一致的概率：2阶段协调者故障，有可能导致部分参与者提交而部分参与者不提交，导致不一致，3阶段协调者如果宕机，参与者默认提交
  - TCC（Try-Confirm-Cancel）
    - 1阶段（试探阶段）：协调者向参与者发起资源预留请求，参与者执行本地事务操作（如写入冻结记录），但不提交最终事务。
    - 2阶段（确认阶段）：协调者向所有参与者发送 Confirm 指令。参与者将预留资源正式生效（如扣减冻结资金、减少库存数量）。
    - 2阶段（取消阶段）：协调者向所有参与者发送取消指令，取消1阶段的数据信息
    - 默认2阶段一定成功，如果2阶段失败，需要定时检测和人工
  - SAGA
    - 核心思想，长事务拆分成多个本地的短事务，如果事务执行中出现错误，会撤销之前所有成功的子事务
  - MQ事务消息
    - 核心思想是通过半消息机制和事务状态回查实现消息与本地事务的协同，
    - 半消息机制
      - 半消息是对消费者不可见的中间状态的消息，仅在本地事务成功后才转为可投递状态
    - 二阶段提交
      - 1阶段：生产者发送半消息到MQ，MQ持久化后返回ACK确认
      - 2阶段：生产者执行本地事务，根据结果向MQ发送COMMIT或ROLLBACK消息
## Seata AT模式（全局锁冲突处理）
  - AT模式 过程
    - 开启全局事务、注册分支事务、储存全局锁、业务数据和回滚日志提交
    - 事务协调者根据所有分支的情况，决定本次全局事务是commit还是rollback
## TCC模式空回滚问题解决方案
  - 问题：
    - 空回滚：参与者未收到try请求导致触发事务回滚，协调者调用cancel，导致报错或数据错误
    - 悬挂：cancel执行后，try请求到达参与者，导致参与者事务一直不释放
  - 解决方案
    - 防止空回滚：预留资源状态检查，确保cancel只在try执行后执行，在try阶段生成唯一id，存在id时才进行操作，不存在则不进行操作
    - 防止悬挂：在执行本地事务之前，根据事务唯一id查询事务当前状态，当前状态为已回滚的状态时，不执行，直接抛出
  - 完整流程设计
    - try阶段：生成唯一事务id，写入冻结记录和事务日志
    - confirm/cancel阶段：
      - confirm：删除冻结记录，标记事务状态为CONFIRMED
      - cancel：检查冻结记录是否存在，存在则解冻，标记事务为cancel，防止后续try执行
    - 超时处理：定时任务扫描tcc_log，将超时未完成的事务，调用cancel 

## 高并发设计

## 限流算法（令牌桶 vs 漏桶实际应用场景）
- 令牌桶：核心是通过固定速率生成令牌，并允许一定程度的突发流量
  - 令牌生成：系统以恒定目标（如每秒10个）向桶中添加令牌，桶的容量有上线，当桶满了时，多的令牌会被丢弃
  - 令牌消耗：每个请求需要获取一定数量的令牌才能被处理，若桶中令牌数量不足时，请求会被拒绝或延迟处理
  - 突发处理：当桶内有足够的令牌时，允许短时间内处理大量请求，但后续请求仍然需要等待令牌生成
  - 适用场景：
    - 突发流量处理，如电商秒杀，api接口限流
    - 资源公平分配，例如允许用户按等级分配api调用
    - 网络带宽管理，允许突发场景，同时限制长期平均速率
- 漏桶算法：核心是通过固定速率处理请求，无论输入速率如何波动，输出速率始终恒定
  - 请求缓存：请求进入漏桶队列，以恒定的速率流出处理
  - 溢出处理：若漏桶队列满了，新请求会被拒绝或丢弃
  - 平滑流量：强制将突发流量转为平稳输出，避免下游系统过载
  - 适用场景
    - 流量整形：如视频流传输，确保数据以恒定速率发送避免卡顿
    - 保护下游服务：防止api调用方突发请求压垮后端系统
    - 网络设备控制：在路由器或交换机中平滑数据包流量
- 对比分析

|   特性    |       令牌桶	       |          漏桶          |
|:-------:|:----------------:|:--------------------:|
| 核心控制目标  |   限制平均速率，允许突发	   |    强制恒定输出速率，平滑突发     |
| 突发处理能力	 |  支持（桶内有令牌即可处理）	  |     不支持（输出速率固定）      |
| 实现复杂度	  | 较高（需维护令牌生成与消耗逻辑） |   较低（仅需队列和固定流出逻辑）    |
| 资源利用率	  | 较高（突发期可快速消耗资源）	  |  较低（可能因固定速率导致资源闲置）   |
| 典型应用场景	 | API限流、秒杀系统、实时通信	 | 视频流传输、数据包整形、保护脆弱下游服务 |

- 实际使用
  - 实际使用中，通常将两种方式混合使用
  - 前端限流：使用令牌桶对应突发请求
  - 后端限流：用漏桶控制对数据库访问，避免过载

## 分库分表（ShardingSphere基因法分片）
- 基因法核心原理
  - 基因法是一种通过在非分片键中嵌入分片键信息的分库分表策略，核心目标是减少跨分片查询并提升关联数据查询效率，其实现原理包含3个关键点
  - 基因编码：将分片键嵌入其他业务字段，例如：用户id为12345，通过取模计算得到基因值（12345%1000） 345，然后将这个基因值用于订单号的构建，订单号为：345_20250301_123456(基因值+时间戳+序列号)
  - 扩容优化：当分片为2的n次幂时，扩容只需要迁移50%的数据
- 实现步骤
  - 分片键设计：
    - 主分片键：user_id，用于高频查询场景
    - 基因字段：order_no，嵌入user_id后4为二进制基因值
  - 基因编码规则
    - 基因替换法：适用雪花算法生成订单号末尾时。将用户id后4位拼接至订单号末尾
    - 基因拼接法：在订单号末尾直接拼接用户id后4位
## 分库分表后全局ID生成（Snowflake时钟回拨问题）
- 雪花算法的核心是 时间戳+机器表示+序列号
- 时钟回拨问题的本质是服务器时间因NTP校准或人工调整或润秒修改的原因导致时间被退回到之前的某一秒，这样就有可能造成同一毫秒内生成的id有重复
- 解决方案
  - 容忍等待策略：原理，当发现回拨时间小于阈值的时候，通过线程休眠等待追赶，发现当前时间比最后一次的时间小时，sleepN秒
  - 备份时钟方案：原理，维护一个逻辑时钟，在检测到物理时钟回拨时，适用逻辑时钟替换物理时间戳
  - 号段预分配策略：预先分配一段序列表，降低雪花算法中时间戳的依赖
  - 混合基因法，将分库分表信息嵌入雪花算法，实现id与分片逻辑强关联


