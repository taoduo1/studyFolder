表述，原理剖析

# AOP
面向切面编程，aop其实是一种思想，是指在执行某个方法的时候不去修改这个方法本身， 同时在这个方法之前或之后实增加一些额外的逻辑，这个思想就是面向切面的思想。
能实现这个功能的方式有很多，比如AspectJ是编译期实现、Spring AOP基于动态代理实现
AspectJ 生成字节码的时候，将额外的逻辑编译进字节码中

aop是什么东西，和oop
aop的基本概念说清楚
1：找对象，@EnableAspectJAutoProxy为容器中做了什么事：给容器中导入了一个AnnontationAwareAspectAutoProxyCreator组件
我们分析出这个组件的继承关系图发现它具有BeanPostProcessor和InstantIationAwareBeanPostProcessor的特性
我们发现在实例化之前（调用构造方法之前执行的）
根据Bean的生命周期中的createBean的环节中触发了后置处理器的before方法
此时在这个环节就会把我们的切面信息@AspectJ的信息标注找出来，然后进行缓存
2：创建对象，创建要切的对象的时候，根据方法进行匹配去找自己的切面（增强器）,然后把增强器和被切的对象创建成一个代理对象
3：代理对象调用：jdk代理和cglib代理，proxyTragetClass为true或者false来指定
通过责任链模式+递归的来进行调用，
先执行异常通知(catch里面执行异常通知的方法)
返回通知：由于没有进行任何的try catch 那么加入抛出异常，就不会执行返回通知的方法而是直接执行到异常通知了
后置通知，代码是在finally里面， 所以他才是总是被执行的
前置通知，直接执行
递归终止条件满足，执行我们的目标方法



工厂模式，模板方法，责任链模式

设计模式
熟悉多线程
集合等基础框架

String、StringBuffer和StringBuilder的异同
String 是不可变的，声明即固定(使用了final关键字，并且char数组设置为private，同时没有暴露可以修改char数组的方法)。
StringBuffer和StringBuilder类则是可变的，通过数组复制的方式，将append的字符串复制进自己初始化的数组中，长度不够时会自己进行扩容，扩容算法（初始化长度的x2+2 仍然不够时，使用原有字符长度+新增字符长度）
StringBuilder不带synchronized 关键字 StringBuffer 带synchronized关键字
需要对字符串进行频繁的修改，不要使用String，否则会造成内存空间的浪费。考虑线程安全的场合使用 StringBuffer，如果不需要考虑线程安全，追求效率的场合可以使用 StringBuilder。

浅拷贝和深拷贝,用的深拷贝的工具类，平常都用什么拷贝方法
浅拷贝：只拷贝当前对象，子对象依旧使用原对象即指针指向原对象
深拷贝：当前对象和子对象，都为新对象 自己使用的话通过将对象序列化为字节流，然后再反序列化，可以实现深拷贝，第三方库的话，阿帕奇的common包有，Gson也有



在Mysql中,可能造成死锁的原因是什么?

1 事务同时更新多个表
当一个事务同时更新多个表并且使用了不同的顺序，可能会导致死锁的发生。例如，事务A首先更新表X，然后获取锁，
并在未释放锁的情况下尝试更新表Y；而事务B首先更新表Y，然后获取锁，并在未释放锁的情况下尝试更新表X。这种情况下，两个事务会相互等待对方的锁释放，从而形成死锁。

2 事务嵌套
当一个事务内部开启了另一个事务，并在内层事务中更新了某个表，而外层事务也需要更新该表的同一行记录时，就有可能发生死锁。因为外层事务需要等待内层事务释放锁，而内层事务需要等待外层事务释放锁。

3 索引顺序不一致
当多个事务按照不同的顺序访问相同的数据行，并且使用了不同的索引时，可能会发生死锁。例如，事务A按照索引1的顺序访问数据行，事务B按照索引2的顺序访问同一组数据行，这样两个事务之间就会产生死锁。

4 不同事务同时更新相同的索引
当多个事务同时更新相同的索引时，可能会导致死锁。这是因为事务在更新索引时会获取对应的锁，并在未释放锁的情况下尝试更新其他数据，从而形成死锁。

MySQL死锁的成因还有以下几点：

并发操作执行顺序不当

数据库负载过高

数据库锁定机制不当

数据库表结构设计不当

假定SQL: select id, xid, data from dummy where xid=?
假定 xid是索引字段 data是非索引字段
请简述这个查询的检索过程

如何判断一个Http请求的body数据的内容格式(xml/json/form)

arr1 = [1,2,2,3,3,3,4,5,5]
请提供代码, 要求返回数组重复的元素个数转换为map
期望结果: map = {1:1, 2:2, 3:3, 4:1, 5:2}


假定一个 非空 整数数组 nums ，除了某个元素只出现一次以外，其余每个元素均出现多次。找出那个只出现了一次的元素。
示例:输入：nums = [4,1,2,1,2] 输出：4

什么是序列化？什么是反序列化？

假定表: score, 存在两列 userid (int) 主键 , income (int) 得分,
假定 得分低于50的为 第一类别, 得分在51-80的为第二类别, 得分高于80的为第三类别,
请编写SQL, 查询每个类别包含的用户数量, 如果某个类别中没有账户, 则报告0, 查询结果必须包含所有三个类别

简单谈一下分布式锁的实现方案

请设计一个方案，用于处理在前后端之间安全传输密码字段

  
mybatis `缓存
一级缓存`（会话级别）：
        必须是同一个会话
        必须是相同的Mapping
        必须是相同的方法
        两个查询中间不能进行增删改
        相同的sql语句，相同的参数
二级缓存：
  会话关闭的时候把数据放进二级缓存，下个会话进行查询的时候，先查询二级缓存，查询不到再查询一级，再查询不到进入数据库查询
        必须是同一个命名空间之下
        必须是相同的statement即同一个mapper接口中的同一个方法
        必须是相同的sql语句和参数
        必须实体类必须实现序列化接口


一条sql查询语句完整的查询过程
    一条sql的完整执行流程可以分为两层，server层和存储引擎层
    查询语句从server层开始，
    1. 通过连接器，打开到数据库的连接，连接器会进行账号密码、权限的校验，这里权限要注意一下，如果一个用户成功建立连接后，即使用管理员修改了权限，这次链接的也不会失效，只会在下次新打开链接的时候失效，链接长时间不动的话，连接器会将他自动断开，这个时间默认是8小时
    2. 是查询缓存，mysql会把之前的查询语句和结果放在缓存中以提高效率，当这个表更新时，会把这个表上的所有缓存全部清除掉，所以目前看的话，缓存还是弊大于利，有可能缓存了一堆，还没怎么用呢，一个update过来，就全部清除了，所以mysql 8.0之后就把缓存废了
    3. 是分析器，这一步是没有命中缓存了，开始真正执行sql，mysql就会对你的语句进行分析，包括语法，别名等
    4. 是优化器，经过了分析器，优化器就开始查看你的表中有哪些索引，决定使用哪个索引，比如说两个表join查询，查询条件各有一张表的某个字段，优化器是先查出a表的数据在根据键值关联到b表还是先查出b表的数据在根据键值关联到a表
    5. 是执行器阶段，开始执行sql语句，在开始执行的时候，先判断你有没有查询sql里表的权限，然后根据表的引擎定义，去使用这个引擎提供的接口
    比如查询select * from T where ID=10;
    比如我们这个例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的：
    调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；
    调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
    执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。
    至此，这个语句就执行完成了。
    对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。
    你会在数据库的慢查询日志中看到一个rows_examined的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。

一条sql更新语句完整的更新过程
    更新语句也会走一遍查询语句的流程
    1. 连接器链接数据库
    2. 分析器通过词法分析和语法分析知道这是一条更新语句
    3. 优化器决定使用ID这个索引
    4. 执行器负责具体执行，找到这一行，然后更新。
    
区别是更新流程还涉及到两个重要的日志模块 redo log(重做日志) 和 binlog(归档日志)
    
Innodb 的redo log是固定大小的，如果可以配置为1组4个文件，每个文件的大小是1G，那么就可以记录4G的数据，从头开始写，写到末尾又回到开头循环写，
    有三个点，一个是write pos 是当前记录的位置，一边写一边向后移，写到3号文件的末尾又回到0号文件的开头
    checkpoint 是当前要擦除的位置，也是一边擦除一边向后移动，擦除记录签要把记录更新到数据文件
    write pos 和checkpoint 之间的是空闲的空间，如果 write pos 追上了 checkpoint 说明空间写满了，先将一部分数据刷进数据文件中，再开始继续。
binlog 是归档日志，保证数据可恢复，redo log是Innodb提供的，mysql 的server层也有自己的日志，就是binlog

update语句执行流程
    update t set c = c+1 where id = 1 ;
    执行步骤为：
    1. 执行器先找到引擎获取到 id= 2 这一行，id是主键，引擎直接用树搜索找到这一行，如果id = 2 这一行所在的数据页本来就在内存中，就直接返回给执行器，否则先从磁盘读入内存，然后再返回
    2. 执行器拿到引擎给的数据，把这个值+1 得到新的一行数据，再调用引擎接口写入这行新数据
    3. 引擎将这行数据更新到内存中，同时将这个更新操作记录到redo log中，此时 redo log处于 prepare 状态，然后告知执行器完成了，随时可以提交事务
    4. 执行器生成这个操作的bin log，并把binlog写入磁盘
    5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的redolog改成commit状态，更新完成
    上面将redo log的写入拆成了两个步骤： prepare和commit， 这就是"两阶段提交"。
    为什么要使用两阶段提交呢，是因为redo log和binlog是两个独立的逻辑，如果不用两阶段提交，就无法保证两日志的一致性。 
    先写redo log后写binlog 则redo log 多数据
    先写binlog 后写redo log 则binlog多数据，



一个http请求执行的完整过程
    1.DNS解析 浏览器进行DNS域名解析，得到对应的IP地址
        首先会搜索浏览器自身的DNS缓存（缓存时间比较短，大概只有1分钟，且只能容纳1000条缓存）
        如果浏览器自身的缓存里面没有找到，那么浏览器会搜索系统自身的DNS缓存
        如果还没有找到，那么尝试从 hosts文件里面去找
        在前面三个过程都没获取到的情况下，浏览器就会发起一个DNS的系统调用，就会向本地配置的首选DNS服务器 （一般是电信运营商提供的，也可以使用像Google提供的DNS服务器）
        发起域名解析请求（通过的是UDP协议向DNS的53端口发起请求，这个请求是递归的请求，也就是运营商的DNS服务器必须得提供给我们该域名的IP地址）
    2.TCP三次握手 根据这个IP，找到对应的服务器建立连接（三次握手）
        刚开始客户端处于 Closed 的状态，而服务端处于 Listen 状态：
        1）第一次握手：客户端向服务端发送一个 SYN 报文（SYN = 1），并指明客户端的初始化序列号 ISN(x)，即图中的 seq = x，表示本报文段所发送的数据的第一个字节的序号。此时客户端处于 SYN_Send 状态。
        2）第二次握手：服务器收到客户端的 SYN 报文之后，会发送 SYN 报文作为应答（SYN = 1），并且指定自己的初始化序列号 ISN(y)，即图中的 seq = y。同时会把客户端的 ISN + 1 作为确认号 ack 的值，
        表示已经收到了客户端发来的的 SYN 报文，希望收到的下一个数据的第一个字节的序号是 x + 1，此时服务器处于 SYN_REVD 的状态。
        3）第三次握手：客户端收到服务器端响应的 SYN 报文之后，会发送一个 ACK 报文，也是一样把服务器的 ISN + 1 作为 ack 的值，表示已经收到了服务端发来的的 SYN 报文，
        希望收到的下一个数据的第一个字节的序号是 y + 1，并指明此时客户端的序列号 seq = x + 1（初始为 seq = x，所以第二个报文段要 +1），此时客户端处于 Establised 状态。
        服务器收到 ACK 报文之后，也处于 Establised 状态，至此，双方建立起了 TCP 连接。
    3.发起HTTP请求 建立TCP连接后发起HTTP请求（一个完整的http请求报文）
    4.服务器响应HTTP请求 服务器响应HTTP请求，浏览器得到html代码（服务器如何响应）
    5.浏览器解析 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等）
    6.浏览器进行页面渲染 浏览器对页面进行渲染呈现给用户
    7.服务器关闭TCP连接 服务器关闭TCP连接（四次挥手）
        第一次挥手：客户端发送一个FIN=M，用来关闭客户端到服务器端的数据传送，客户端进入FIN_WAIT_1状态。意思是说"我客户端没有数据要发给你了"，但是如果你服务器端还有数据没有发送完成，则不必急着关闭连接，可以继续发送数据。
        第二次挥手：服务器端收到FIN后，先发送ack=M+1，告诉客户端，你的请求我收到了，但是我还没准备好，请继续你等我的消息。这个时候客户端就进入FIN_WAIT_2 状态，继续等待服务器端的FIN报文。
        第三次挥手：当服务器端确定数据已发送完成，则向客户端发送FIN=N报文，告诉客户端，好了，我这边数据发完了，准备好关闭连接了。服务器端进入LAST_ACK状态。
        第四次挥手：客户端收到FIN=N报文后，就知道可以关闭连接了，但是他还是不相信网络，怕服务器端不知道要关闭，所以发送ack=N+1后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。服务器端收到ACK后，就知道可以断开连接了。客户端等待了2MSL后依然没有收到回复，则证明服务器端已正常关闭，那好，我客户端也可以关闭连接了。最终完成了四次握手。
        为什么连接的时候是三次握手，关闭的时候却是四次握手？
        因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。
        但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。
        只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四次挥手。

Spring MVC框架的工作流程如下：
（1）用户通过浏览器向服务器发送请求，请求会被Spring MVC的前端控制器DispatcherServlet所拦截。
（2）DispatcherServlet拦截到请求后，会调用HandlerMapping处理器映射器。
（3）处理器映射器根据请求URL找到具体的处理器，生成处理器对象及处理器拦截器（如果有则生成）一并返回给DispatcherServlet。
（4）DispatcherServlet会通过返回信息选择合适的0HandlerAdapter（处理器适配器）。
（5）HandlerAdapter会调用并执行Handler（处理器），这里的处理器指的就是程序中编写的Controller类，也被称之为后端控制器。
（6）Controller执行完成后，会返回一个ModelAndView对象，该对象中会包含视图名或包含模型和视图名。
（7）HandlerAdapter将ModelAndView对象返回给DispatcherServlet。
（8）DispatcherServlet会根据ModelAndView对象选择一个合适的ViewReslover（视图解析器）。
（9）ViewReslover解析后，会向DispatcherServlet中返回具体的View（视图）。
（10）DispatcherServlet对View进行渲染（即将模型数据填充至视图中）。
（11）视图渲染结果会返回给客户端浏览器显示。


分布式锁的实现方案
    分布式锁要解决的问题主要是 多节点情况下，对同一资源访问需要保证一致性，比如扣存款的业务逻辑，每笔扣款在进行的时候，需要保证扣之前的约和扣之后的余额是一致的，也就是说扣之前是300，扣了100，还有200，别的线程进来的时候也是对200进行扣款。
    现在实现分布式锁我用的还是redis的redisson去实现的，redisson的源码还是基于lua脚本实现的，redisson就是依赖redis执行模式是单线程执行的，保证了整个加锁和设置超时时间操作的原子性，
    并且还有子线程给当前锁重新设置超时时间 
    
消息队列


前后端密码传输的安全方案
并发量大怎么控制
    1.nginx去控制流量，设置最大请求数量

面试上个项目负责了什么
什么是序列化？什么是反序列化？

死锁：
    死锁简单来说就是两个或两个以上线程在执行的过程中去争夺同样一个共享资源，造成相互等待的一个现象，如果没有外部的干预，线程会一直阻塞无法向下执行，这样一直处于等待的线程我们叫它死锁线程。
    造成死锁的条件有4个，1：互斥，共享资源X和Y只能被一个线程占用。2，请求保持，线程T1已经取得共享资源X，在等待共享资源Y的时候，不释放共享资源X，3，不可抢占，其他线程不能强行抢占线程T1占有的资源，4，循环等待，两个或多个线程互相等待对方的资源释放。
    解决就是我们去破坏上面这几个条件，除了条件1是无法被破坏的，破坏其他条件就可以消除死锁，
    比如请求保持，可以一次性申请所有的资源，
    破坏不可抢占可以在线程A去申请资源Y的时候，如果申请不到，主动释放自己所持有的线程X
    破坏循环等待的话，可以按序申请，先申请

分段锁
 将资源分段，比如某商品有200个，将200个分成10段，每段20个，在每个段上加锁，concurrentHasMap



一、Java核心基础
JVM与性能调优


并发容器（ConcurrentHashMap分段锁 vs CAS） 暂时搁置

响应式编程（Reactor、WebFlux核心思想） 暂时搁置

二、主流框架与中间件
Spring生态



ORM框架

MyBatis一级/二级缓存问题及解决方案

Hibernate N+1查询问题优化（Batch Fetching）

分布式中间件

Redis分布式锁（Redlock算法争议）

Kafka高吞吐原理（PageCache、零拷贝）

RocketMQ事务消息实现（二阶段提交）

Dubbo SPI扩展机制（自适应扩展点）

三、分布式系统设计
微服务架构

服务注册发现（CAP理论下Eureka与Nacos对比）

熔断降级策略（Hystrix vs Sentinel）

链路追踪（SkyWalking采样率配置）

分布式事务

Seata AT模式（全局锁冲突处理）

TCC模式空回滚问题解决方案

高并发设计

限流算法（令牌桶 vs 漏桶实际应用场景）

分库分表（ShardingSphere基因法分片）

热点数据缓存（本地缓存+Redis多级缓存）

四、数据库与存储
MySQL优化

索引失效场景（最左前缀、隐式类型转换）

InnoDB事务隔离级别（MVCC实现原理）

分库分表后全局ID生成（Snowflake时钟回拨问题）

NoSQL选型

MongoDB聚合管道优化

Elasticsearch倒排索引与分词器选择

七、源码与底层原理
框架源码

Spring Bean生命周期（BeanPostProcessor扩展点）

HashMap红黑树转换阈值（链表长度≥8且数组长度≥64）

JUC源码

ThreadPoolExecutor任务拒绝策略（CallerRunsPolicy适用场景）

ConcurrentHashMap扩容机制（多线程协助扩容）

五、系统设计与架构
设计模式实战

模板方法模式在Spring中的应用（JdbcTemplate）

策略模式在支付系统中的应用（多支付渠道路由）

高可用设计

异地多活架构数据同步方案（CAP权衡）

灰度发布方案（基于流量染色）

性能优化

慢SQL排查（Explain执行计划）

JVM调优案例（Full GC频繁问题定位）

六、项目经验与软技能
项目深度

技术选型对比（如Kafka vs RabbitMQ选型原因）

复杂问题解决案例（如分布式锁失效导致超卖）

架构设计能力

设计一个秒杀系统（库存扣减方案、流量削峰）

设计一个即时通讯系统（消息可靠投递、离线存储）

软技能

技术债务管理经验

跨团队协作冲突解决（如需求优先级争执）

八、前沿技术考察
云原生

Kubernetes Pod调度策略（亲和性与反亲和性）

Service Mesh（Istio流量管理）

新趋势

Serverless在Java中的落地挑战

JDK 21虚拟线程（Loom项目）对线程池的影响
